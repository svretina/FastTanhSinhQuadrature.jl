var documenterSearchIndex = {"docs":
[{"location":"benchmarks/#Benchmarks","page":"Benchmarks","title":"Benchmarks","text":"Comparison of FastTanhSinhQuadrature.jl vs FastGaussQuadrature.jl.\n\nSystem:\n\nCPU: Intel(R) Core(TM) Ultra 7 155U\nThreads: 1 (Single-threaded execution)","category":"section"},{"location":"benchmarks/#Results","page":"Benchmarks","title":"Results","text":"Legend:\n\nTS: FastTanhSinhQuadrature.integrate\nTS SIMD: FastTanhSinhQuadrature.integrate_avx (using LoopVectorization)\nGQ: FastGaussQuadrature.gausslegendre\n\nFunction Domain Points TS (ns) TS SIMD (ns) GQ (ns) Ratio (TS/GQ) Ratio (TS SIMD/GQ)\nexp(x) [-1, 1] 5 33.09 14.27 33.03 1.00 0.43\nexp(x) [-1, 1] 50 322.87 81.99 176.68 1.83 0.46\nexp(x) [-1, 1] 500 3374.75 782.08 1665.50 2.03 0.47\nsin(x)^2 [-1, 1] 5 40.39 23.38 32.63 1.24 0.72\nsin(x)^2 [-1, 1] 50 404.32 145.48 176.75 2.29 0.82\nsin(x)^2 [-1, 1] 500 4361.71 1409.10 1768.40 2.47 0.80\n1/(1+25x^2) [-1, 1] 5 3.00 3.75 17.35 0.17 0.22\n1/(1+25x^2) [-1, 1] 50 41.82 39.17 34.77 1.20 1.13\n1/(1+25x^2) [-1, 1] 500 477.21 213.24 320.39 1.49 0.67\nsqrt(1-x^2) [-1, 1] 5 4.06 4.69 20.31 0.20 0.23\nsqrt(1-x^2) [-1, 1] 50 68.01 45.31 69.68 0.98 0.65\nsqrt(1-x^2) [-1, 1] 500 636.53 313.13 743.43 0.86 0.42\nx^2 [-1, 1] 5 2.01 3.04 19.86 0.10 0.15\nx^2 [-1, 1] 50 17.72 21.68 38.07 0.47 0.57\nx^2 [-1, 1] 500 213.31 54.97 273.19 0.78 0.20\nlog(1-x) [-1, 1] 5 38.06 30.29 34.32 1.11 0.88\nlog(1-x) [-1, 1] 50 371.88 187.29 214.70 1.73 0.87\nlog(1-x) [-1, 1] 500 4117.38 1978.80 2117.80 1.94 0.93\nx^3 [-1, 1] 5 2.23 3.14 18.65 0.12 0.17\nx^3 [-1, 1] 50 21.86 22.09 35.69 0.61 0.62\nx^3 [-1, 1] 500 239.28 60.84 267.62 0.89 0.23\nx^3+x^2+x+1 [-1, 1] 5 3.98 4.00 20.12 0.20 0.20\nx^3+x^2+x+1 [-1, 1] 50 41.75 26.31 36.58 1.14 0.72\nx^3+x^2+x+1 [-1, 1] 500 450.22 80.03 263.54 1.71 0.30","category":"section"},{"location":"benchmarks/#Analysis","page":"Benchmarks","title":"Analysis","text":"Polynomials: FastTanhSinhQuadrature with SIMD acceleration (x^2, x^3) is significantly faster (up to ~3-5x) than Gauss-Legendre quadrature.\nSingularities: Functions like sqrt(1-x^2) and log(1-x) are handled handled very efficiently, often matching or outperforming Gaussian quadrature due to the double exponential clustering of nodes.\nRunge Function: 1/(1+25x^2) also shows competitive performance, especially with SIMD.\n\nIn summary, for smooth analytic functions, Gaussian quadrature (standard non-SIMD integrate vs GQ) is faster due to fewer nodes required for exactness using polynomials. However, FastTanhSinhQuadrature's SIMD implementation often bridges or exceeds this gap, and it is the superior choice for singular integrands.","category":"section"},{"location":"api/#API-Reference","page":"API Reference","title":"API Reference","text":"Pages = [\"api.md\"]","category":"section"},{"location":"api/#Public-Functions","page":"API Reference","title":"Public Functions","text":"","category":"section"},{"location":"api/#High-Level-API","page":"API Reference","title":"High-Level API","text":"","category":"section"},{"location":"api/#1D-Integration","page":"API Reference","title":"1D Integration","text":"","category":"section"},{"location":"api/#2D-Integration","page":"API Reference","title":"2D Integration","text":"","category":"section"},{"location":"api/#3D-Integration","page":"API Reference","title":"3D Integration","text":"","category":"section"},{"location":"api/#Lower-level-Utilities","page":"API Reference","title":"Lower-level Utilities","text":"","category":"section"},{"location":"api/#All-Functions","page":"API Reference","title":"All Functions","text":"","category":"section"},{"location":"api/#FastTanhSinhQuadrature.quad","page":"API Reference","title":"FastTanhSinhQuadrature.quad","text":"quad(f::Function, [xmin, xmax]; tol=1e-12, max_levels=10)\n\nHigh-level interface for Tanh-Sinh quadrature. Automatically detects dimensions (1D, 2D, or 3D)  and chooses the most efficient implementation.\n\nIf xmin and xmax are absent, integrates over [-1, 1] (1D).\nUses SIMD-accelerated (_avx) implementation for Float32/Float64.\nUses higher-precision implementation for other types (e.g., BigFloat).\nAutomatically converts AbstractVector to SVector for multi-dimensional integration.\n\n\n\n\n\n","category":"function"},{"location":"api/#FastTanhSinhQuadrature.integrate1D","page":"API Reference","title":"FastTanhSinhQuadrature.integrate1D","text":"integrate1D(::Type{T}, f::Function, N::Int) where {T<:Real}\n\nCalculate the integral of f over [-1, 1] using N Tanh-Sinh quadrature points in precision T.\n\n\n\n\n\nintegrate1D(f, x, w, h)\n\nCalculate the integral of f over [-1, 1] using pre-computed nodes x, weights w, and step size h.\n\n\n\n\n\nintegrate1D(f, xmin, xmax, x, w, h)\n\nCalculate the integral of f over [xmin, xmax] using pre-computed nodes x, weights w, and step size h.\n\n\n\n\n\n","category":"function"},{"location":"api/#FastTanhSinhQuadrature.integrate1D_avx","page":"API Reference","title":"FastTanhSinhQuadrature.integrate1D_avx","text":"integrate1D_avx(f, x, w, h)\n\nSIMD-accelerated 1D integration over [-1, 1] Using LoopVectorization.  Requires f to be compatible with @turbo. Only beneficial for Float32/Float64.\n\n\n\n\n\nintegrate1D_avx(f, xmin, xmax, x, w, h)\n\nSIMD-accelerated 1D integration over [xmin, xmax] Using LoopVectorization.\n\n\n\n\n\n","category":"function"},{"location":"api/#FastTanhSinhQuadrature.adaptive_integrate_1D","page":"API Reference","title":"FastTanhSinhQuadrature.adaptive_integrate_1D","text":"adaptive_integrate_1D(::Type{T}, f::Function, a, b; tol::Real=1e-12, max_levels::Int=10)\n\nAdaptive 1D Tanh-Sinh integration over [a, b]. Starts with a coarse grid (h ≈ tmax/2) and halves  the step size at each level. Reuses function evaluations from previous levels by only computing new (odd-indexed) nodes. Exploits symmetry around the center of the interval.\n\n\n\n\n\n","category":"function"},{"location":"api/#FastTanhSinhQuadrature.integrate2D","page":"API Reference","title":"FastTanhSinhQuadrature.integrate2D","text":"integrate2D(f, x, w, h)\n\nCalculate the 2D integral of f over [-1, 1]^2 using pre-computed nodes/weights.\n\n\n\n\n\nintegrate2D(f, xmin, xmax, x, w, h)\n\nCalculate the 2D integral of f over [xmin, xmax] (with xmin, xmax::SVector{2}) using pre-computed nodes/weights.\n\n\n\n\n\n","category":"function"},{"location":"api/#FastTanhSinhQuadrature.integrate2D_avx","page":"API Reference","title":"FastTanhSinhQuadrature.integrate2D_avx","text":"integrate2D_avx(f, xmin, xmax, x, w, h)\n\nSIMD-accelerated 2D integration over [xmin, xmax] Using LoopVectorization.\n\n\n\n\n\n","category":"function"},{"location":"api/#FastTanhSinhQuadrature.adaptive_integrate_2D","page":"API Reference","title":"FastTanhSinhQuadrature.adaptive_integrate_2D","text":"adaptive_integrate_2D(::Type{T}, f::Function, xmin::SVector{2,T}, xmax::SVector{2,T}; tol::Real=1e-10, max_levels::Int=8)\n\nAdaptive 2D Tanh-Sinh integration over a rectangle. Reuses indices by only evaluating new points  where at least one coordinate corresponds to an odd multiple of the halved step size h.  Exploits 4-way quadrant symmetry and 2-way axis symmetry.\n\n\n\n\n\n","category":"function"},{"location":"api/#FastTanhSinhQuadrature.integrate3D","page":"API Reference","title":"FastTanhSinhQuadrature.integrate3D","text":"integrate3D(f, x, w, h)\n\nCalculate the 3D integral of f over [-1, 1]^3 using pre-computed nodes/weights.\n\n\n\n\n\nintegrate3D(f, xmin, xmax, x, w, h)\n\nCalculate the 3D integral of f over [xmin, xmax] (with xmin, xmax::SVector{3}).\n\n\n\n\n\n","category":"function"},{"location":"api/#FastTanhSinhQuadrature.integrate3D_avx","page":"API Reference","title":"FastTanhSinhQuadrature.integrate3D_avx","text":"integrate3D_avx(f, x, w, h)\n\nSIMD-accelerated 3D integral over [-1, 1]^3.\n\n\n\n\n\nintegrate3D_avx(f, xmin, xmax, x, w, h)\n\nSIMD-accelerated 3D integral over [xmin, xmax].\n\n\n\n\n\n","category":"function"},{"location":"api/#FastTanhSinhQuadrature.adaptive_integrate_3D","page":"API Reference","title":"FastTanhSinhQuadrature.adaptive_integrate_3D","text":"adaptive_integrate_3D(::Type{T}, f::Function, xmin::SVector{3,T}, xmax::SVector{3,T}; tol::Real=1e-8, max_levels::Int=5)\n\nAdaptive 3D Tanh-Sinh integration over a box. Reuses old points and exploits 8-way octant  symmetry, 4-way plane symmetry, and 2-way axis symmetry to minimize function evaluations.\n\n\n\n\n\n","category":"function"},{"location":"api/#FastTanhSinhQuadrature.tanhsinh","page":"API Reference","title":"FastTanhSinhQuadrature.tanhsinh","text":"tanhsinh(::Type{T}, N::Int) where {T<:AbstractFloat}\n\nGenerate Tanh-Sinh quadrature nodes x, weights w, and step size h for a given floating point type T and number of points N.\n\n\n\n\n\n","category":"function"},{"location":"api/#FastTanhSinhQuadrature.adaptive_integrate_1D-Union{Tuple{S}, Tuple{T}, Tuple{Type{T}, S, Any, Any}} where {T<:Real, S}","page":"API Reference","title":"FastTanhSinhQuadrature.adaptive_integrate_1D","text":"adaptive_integrate_1D(::Type{T}, f::Function, a, b; tol::Real=1e-12, max_levels::Int=10)\n\nAdaptive 1D Tanh-Sinh integration over [a, b]. Starts with a coarse grid (h ≈ tmax/2) and halves  the step size at each level. Reuses function evaluations from previous levels by only computing new (odd-indexed) nodes. Exploits symmetry around the center of the interval.\n\n\n\n\n\n","category":"method"},{"location":"api/#FastTanhSinhQuadrature.adaptive_integrate_2D-Union{Tuple{S}, Tuple{T}, Tuple{Type{T}, S, StaticArraysCore.SVector{2, T}, StaticArraysCore.SVector{2, T}}} where {T<:Real, S}","page":"API Reference","title":"FastTanhSinhQuadrature.adaptive_integrate_2D","text":"adaptive_integrate_2D(::Type{T}, f::Function, xmin::SVector{2,T}, xmax::SVector{2,T}; tol::Real=1e-10, max_levels::Int=8)\n\nAdaptive 2D Tanh-Sinh integration over a rectangle. Reuses indices by only evaluating new points  where at least one coordinate corresponds to an odd multiple of the halved step size h.  Exploits 4-way quadrant symmetry and 2-way axis symmetry.\n\n\n\n\n\n","category":"method"},{"location":"api/#FastTanhSinhQuadrature.adaptive_integrate_3D-Union{Tuple{S}, Tuple{T}, Tuple{Type{T}, S, StaticArraysCore.SVector{3, T}, StaticArraysCore.SVector{3, T}}} where {T<:Real, S}","page":"API Reference","title":"FastTanhSinhQuadrature.adaptive_integrate_3D","text":"adaptive_integrate_3D(::Type{T}, f::Function, xmin::SVector{3,T}, xmax::SVector{3,T}; tol::Real=1e-8, max_levels::Int=5)\n\nAdaptive 3D Tanh-Sinh integration over a box. Reuses old points and exploits 8-way octant  symmetry, 4-way plane symmetry, and 2-way axis symmetry to minimize function evaluations.\n\n\n\n\n\n","category":"method"},{"location":"api/#FastTanhSinhQuadrature.integrate1D-Union{Tuple{T}, Tuple{Type{T}, Function, Int64}} where T<:Real","page":"API Reference","title":"FastTanhSinhQuadrature.integrate1D","text":"integrate1D(::Type{T}, f::Function, N::Int) where {T<:Real}\n\nCalculate the integral of f over [-1, 1] using N Tanh-Sinh quadrature points in precision T.\n\n\n\n\n\n","category":"method"},{"location":"api/#FastTanhSinhQuadrature.integrate1D-Union{Tuple{W}, Tuple{X}, Tuple{S}, Tuple{T}, Tuple{S, T, T, X, W, T}} where {T<:Real, S, X<:AbstractVector{T}, W<:AbstractVector{T}}","page":"API Reference","title":"FastTanhSinhQuadrature.integrate1D","text":"integrate1D(f, xmin, xmax, x, w, h)\n\nCalculate the integral of f over [xmin, xmax] using pre-computed nodes x, weights w, and step size h.\n\n\n\n\n\n","category":"method"},{"location":"api/#FastTanhSinhQuadrature.integrate1D-Union{Tuple{X}, Tuple{T}, Tuple{X, AbstractVector{T}, AbstractVector{T}, T}} where {T<:Real, X}","page":"API Reference","title":"FastTanhSinhQuadrature.integrate1D","text":"integrate1D(f, x, w, h)\n\nCalculate the integral of f over [-1, 1] using pre-computed nodes x, weights w, and step size h.\n\n\n\n\n\n","category":"method"},{"location":"api/#FastTanhSinhQuadrature.integrate1D_avx-Union{Tuple{S}, Tuple{T}, Tuple{S, AbstractVector{T}, AbstractVector{T}, T}} where {T<:Real, S}","page":"API Reference","title":"FastTanhSinhQuadrature.integrate1D_avx","text":"integrate1D_avx(f, x, w, h)\n\nSIMD-accelerated 1D integration over [-1, 1] Using LoopVectorization.  Requires f to be compatible with @turbo. Only beneficial for Float32/Float64.\n\n\n\n\n\n","category":"method"},{"location":"api/#FastTanhSinhQuadrature.integrate1D_avx-Union{Tuple{S}, Tuple{T}, Tuple{S, T, T, AbstractVector{T}, AbstractVector{T}, T}} where {T<:Real, S}","page":"API Reference","title":"FastTanhSinhQuadrature.integrate1D_avx","text":"integrate1D_avx(f, xmin, xmax, x, w, h)\n\nSIMD-accelerated 1D integration over [xmin, xmax] Using LoopVectorization.\n\n\n\n\n\n","category":"method"},{"location":"api/#FastTanhSinhQuadrature.integrate2D-Union{Tuple{W}, Tuple{X}, Tuple{S}, Tuple{T}, Tuple{S, StaticArraysCore.SVector{2, T}, StaticArraysCore.SVector{2, T}, X, W, T}} where {T<:Real, S, X<:AbstractVector{T}, W<:AbstractVector{T}}","page":"API Reference","title":"FastTanhSinhQuadrature.integrate2D","text":"integrate2D(f, xmin, xmax, x, w, h)\n\nCalculate the 2D integral of f over [xmin, xmax] (with xmin, xmax::SVector{2}) using pre-computed nodes/weights.\n\n\n\n\n\n","category":"method"},{"location":"api/#FastTanhSinhQuadrature.integrate2D-Union{Tuple{W}, Tuple{X}, Tuple{S}, Tuple{T}, Tuple{S, X, W, T}} where {T<:Real, S, X<:AbstractVector{T}, W<:AbstractVector{T}}","page":"API Reference","title":"FastTanhSinhQuadrature.integrate2D","text":"integrate2D(f, x, w, h)\n\nCalculate the 2D integral of f over [-1, 1]^2 using pre-computed nodes/weights.\n\n\n\n\n\n","category":"method"},{"location":"api/#FastTanhSinhQuadrature.integrate2D_avx-Union{Tuple{W}, Tuple{X}, Tuple{S}, Tuple{T}, Tuple{S, StaticArraysCore.SVector{2, T}, StaticArraysCore.SVector{2, T}, X, W, T}} where {T<:Real, S, X<:AbstractVector{T}, W<:AbstractVector{T}}","page":"API Reference","title":"FastTanhSinhQuadrature.integrate2D_avx","text":"integrate2D_avx(f, xmin, xmax, x, w, h)\n\nSIMD-accelerated 2D integration over [xmin, xmax] Using LoopVectorization.\n\n\n\n\n\n","category":"method"},{"location":"api/#FastTanhSinhQuadrature.integrate3D-Union{Tuple{W}, Tuple{X}, Tuple{S}, Tuple{T}, Tuple{S, StaticArraysCore.SVector{3, T}, StaticArraysCore.SVector{3, T}, X, W, T}} where {T<:Real, S, X<:AbstractVector{T}, W<:AbstractVector{T}}","page":"API Reference","title":"FastTanhSinhQuadrature.integrate3D","text":"integrate3D(f, xmin, xmax, x, w, h)\n\nCalculate the 3D integral of f over [xmin, xmax] (with xmin, xmax::SVector{3}).\n\n\n\n\n\n","category":"method"},{"location":"api/#FastTanhSinhQuadrature.integrate3D-Union{Tuple{W}, Tuple{X}, Tuple{S}, Tuple{T}, Tuple{S, X, W, T}} where {T<:Real, S, X<:AbstractVector{T}, W<:AbstractVector{T}}","page":"API Reference","title":"FastTanhSinhQuadrature.integrate3D","text":"integrate3D(f, x, w, h)\n\nCalculate the 3D integral of f over [-1, 1]^3 using pre-computed nodes/weights.\n\n\n\n\n\n","category":"method"},{"location":"api/#FastTanhSinhQuadrature.integrate3D_avx-Union{Tuple{W}, Tuple{X}, Tuple{S}, Tuple{T}, Tuple{S, StaticArraysCore.SVector{3, T}, StaticArraysCore.SVector{3, T}, X, W, T}} where {T<:Real, S, X<:AbstractVector{T}, W<:AbstractVector{T}}","page":"API Reference","title":"FastTanhSinhQuadrature.integrate3D_avx","text":"integrate3D_avx(f, xmin, xmax, x, w, h)\n\nSIMD-accelerated 3D integral over [xmin, xmax].\n\n\n\n\n\n","category":"method"},{"location":"api/#FastTanhSinhQuadrature.integrate3D_avx-Union{Tuple{W}, Tuple{X}, Tuple{S}, Tuple{T}, Tuple{S, X, W, T}} where {T<:Real, S, X<:AbstractVector{T}, W<:AbstractVector{T}}","page":"API Reference","title":"FastTanhSinhQuadrature.integrate3D_avx","text":"integrate3D_avx(f, x, w, h)\n\nSIMD-accelerated 3D integral over [-1, 1]^3.\n\n\n\n\n\n","category":"method"},{"location":"api/#FastTanhSinhQuadrature.quad-Union{Tuple{T}, Tuple{Function, T, T}} where T<:Real","page":"API Reference","title":"FastTanhSinhQuadrature.quad","text":"quad(f::Function, [xmin, xmax]; tol=1e-12, max_levels=10)\n\nHigh-level interface for Tanh-Sinh quadrature. Automatically detects dimensions (1D, 2D, or 3D)  and chooses the most efficient implementation.\n\nIf xmin and xmax are absent, integrates over [-1, 1] (1D).\nUses SIMD-accelerated (_avx) implementation for Float32/Float64.\nUses higher-precision implementation for other types (e.g., BigFloat).\nAutomatically converts AbstractVector to SVector for multi-dimensional integration.\n\n\n\n\n\n","category":"method"},{"location":"api/#FastTanhSinhQuadrature.quad_split-Union{Tuple{T}, Tuple{Function, T, T, T}} where T<:Real","page":"API Reference","title":"FastTanhSinhQuadrature.quad_split","text":"quad_split(f, c, [xmin, xmax]; tol=1e-12, max_levels=10)\n\nSplit the integration domain at point c (singularity) and integrate sub-domains separately.\n\n\n\n\n\n","category":"method"},{"location":"api/#FastTanhSinhQuadrature.t_w_max-Union{Tuple{Type{T}}, Tuple{T}, Tuple{Type{T}, Int64}} where T<:Real","page":"API Reference","title":"FastTanhSinhQuadrature.t_w_max","text":"t_w_max(::Type{T}, D::Int=1) where {T<:Real}\n\nCalculate the maximum t to avoid weight underflow (Eq. 15 in arXiv:2007.15057). Ensures (ψ'(t))^calD >= floatmin(T) where calD = max(1, D-1).\n\n\n\n\n\n","category":"method"},{"location":"api/#FastTanhSinhQuadrature.t_x_max-Union{Tuple{Type{T}}, Tuple{T}} where T<:Real","page":"API Reference","title":"FastTanhSinhQuadrature.t_x_max","text":"t_x_max(::Type{T}) where {T<:Real}\n\nCalculate the maximum t to avoid abscissae underflow (Eq. 13 in arXiv:2007.15057). Ensures 1 - |t| >= floatmin(T).\n\n\n\n\n\n","category":"method"},{"location":"api/#FastTanhSinhQuadrature.tanhsinh-Union{Tuple{T}, Tuple{Type{T}, Int64}} where T<:AbstractFloat","page":"API Reference","title":"FastTanhSinhQuadrature.tanhsinh","text":"tanhsinh(::Type{T}, N::Int) where {T<:AbstractFloat}\n\nGenerate Tanh-Sinh quadrature nodes x, weights w, and step size h for a given floating point type T and number of points N.\n\n\n\n\n\n","category":"method"},{"location":"api/#FastTanhSinhQuadrature.tmax-Union{Tuple{Type{T}}, Tuple{T}, Tuple{Type{T}, Int64}} where T<:Real","page":"API Reference","title":"FastTanhSinhQuadrature.tmax","text":"tmax(::Type{T}, D::Int=1) where {T<:Real}\n\nFind the optimal window limit tmax considering abscissae and weight underflow (Eq. 14 in arXiv:2007.15057).\n\n\n\n\n\n","category":"method"},{"location":"theory/#Tanh-Sinh-Quadrature","page":"Theory","title":"Tanh-Sinh Quadrature","text":"The quadrature computes integrals of the form\n\nmathcalI=int_-1^1 f(x) dx\n\nThe method is based on a variable transformation which maps the original domain x in (-11) onto the entire real axis t in (-infty infty) using the transformation:\n\nx = Psi(t) = tanhleft(fracpi2 sinh tright)\n\nThe derivative (Jacobian) of this transformation is:\n\nPsi(t) = fracfracpi2 cosh tcosh^2left(fracpi2 sinh tright)\n\nThe integral then becomes:\n\nmathcalI = int_-infty^infty g(t) dt quad g(t)= f(Psi(t)) Psi(t)\n\nSince the method is specific for the x in (-11) domain, one must cast the desired integral to this domain by the linear substitution:\n\nx(u)=fracb+a2+fracb-a2u\n\nThis transformation changes an arbitrary interval ab to -11, hence\n\nint_a^b f(x)dx= fracb-a2int_-1^1 f(x(u))du = fracb-a2int_-infty^infty f(x(u(t))) w(t) dt","category":"section"},{"location":"theory/#Transformation-Visualization","page":"Theory","title":"Transformation Visualization","text":"The key to the Tanh-Sinh quadrature's effectiveness lies in how the transformation maps the integration points. While the discretization in the transformed t-domain uses equidistant notes (t_i = ih), the mapping x = tanh(fracpi2 sinh t) causes these corresponding x_i nodes to cluster double exponentially fast near the endpoints -1 and +1 of the original domain. This dense clustering allows the quadrature to accurately resolve functions even when they have singularities at the boundaries, as the weights decay rapidly enough to suppress the singularity.\n\n<div style=\"text-align: center;\">\n  <img src=\"figure_1.png\" alt=\"Transformation Visualization\" width=\"400\">\n  <br>\n  <em>Figure 1: Visualization of the Tanh-Sinh variable transformation. Source: <a href=\"https://arxiv.org/abs/2007.15057\">arXiv:2007.15057</a>.</em>\n</div>","category":"section"},{"location":"theory/#Discretization","page":"Theory","title":"Discretization","text":"We approximate the infinite integral using the trapezoidal rule with step size h:\n\nmathcalI_h = sum_i=-infty^infty h g(t_i) = sum_i=-infty^infty h Psi(t_i) f(Psi(t_i))\n\nwhere t_i = ih. Because the transformed integrand g(t) decays double exponentially (like exp(-fracpi2 e^t)) as t to infty, we can truncate the infinite sum to a finite window -t_n t_n with negligible error:\n\nmathcalI approx Q_h^n = sum_i=-n^n h Psi(t_i) f(Psi(t_i))","category":"section"},{"location":"theory/#Error-Estimation-and-Convergence","page":"Theory","title":"Error Estimation and Convergence","text":"For an integrand f(x) that is regular in a strip of width d in the complex plane around the interval -1 1, the error of the tanh-sinh quadrature decreases exponentially with the number of evaluation points N = 2n+1. Specifically, the error is of the order:\n\nmathcalI - Q_h^n approx mathcalOleft(expleft(-fracpi d Nln(2 d N)right)right)\n\nThis rapid convergence rate is the hallmark of double exponential formulas.","category":"section"},{"location":"theory/#Optimal-Step-Size-and-Truncation","page":"Theory","title":"Optimal Step Size and Truncation","text":"The choice of the step size h and the number of points N are coupled. To balance the discretization error (from the trapezoidal rule) and the truncation error (from cutting off the infinite sum), the optimal step size h for a given N is approximately:\n\nh_opt approx frac2N ln(pi d N)\n\nHowever, in floating-point arithmetic, we are limited by the machine precision. We cannot transform points arbitrarily close to pm 1 without hitting the underflow limit or precision bound of the floating-point type.\n\nThis leads to a maximal step size constraint to ensure numerical stability. If t_max is the largest argument such that we can still distinguish Psi(t_max) from 1 (or weights from 0), then we must have:\n\nh_max = fract_maxn\n\nTypically, t_max is determined by the condition where the weights Psi(t) underflow to zero or the nodes Psi(t) become indistinguishable from pm 1 in the given precision.","category":"section"},{"location":"theory/#Numerical-Stability-Notes","page":"Theory","title":"Numerical Stability Notes","text":"When dealing with finite precision floating point numbers, numerical instabilities can arise.\n\nThe quadrature scheme depends crucially on the evaluations very close to the end-points of the integration domain. The most important cause of numerical instabilities is numerical underflow.\n\nBoth the smallest weight and abscissa value are determined by the window size t_n. The smallest positive normalized floating point number is F_min=2^L.\n\nFor the weights to avoid the numerical underflow we need:\n\nt_max^w = max t Psi(t) geq F_min\n\nSimilarly the smallest abscissa should exceed the machine epsilon / underflow limit relative to the endpoint:\n\nt_max^x = max t  t leq Psi^-1(1-F_min)\n\nSince these conditions need to be satisfied simultaneously we introduce:\n\nt_max^xw = min t_max^x t_max^w \n\nIt is crucial to ensure h is chosen such that nh le t_max^xw. These limits ensure that the quadrature points remain within the range where the function f(x) can be reliably evaluated and where the Jacobian weights carry meaningful values without underflowing to zero.","category":"section"},{"location":"theory/#Adaptive-Integration-Strategy","page":"Theory","title":"Adaptive Integration Strategy","text":"To achieve a desired accuracy without manually tuning the number of points N, we implement an adaptive refinement strategy:\n\nGrid Refinement: Starting from a coarse step size h_0 approx t_max2, we halve the step size at each iteration (h_k+1 = h_k  2).\nNode Reuse: Because h_k+1 = h_k  2, all nodes from iteration k are preserved in iteration k+1 (they correspond to the even-indexed nodes x_2i^k+1).\nEfficiency: At each step, we only evaluate the function at the new nodes (odd indices x_2i+1^k+1 in the refined grid). This reduces the number of expensive function calls by a factor of 2 compared to recomputing the whole sum.\nMulti-Dimensional Symmetry: we exploit the symmetry of the Tanh-Sinh weights (w(t) = w(-t)) and nodes (Psi(t) = -Psi(-t)). For 2D and 3D integrals, this means we only iterate over one \"corner\" of the domain and use reflections (4-way in 2D, 8-way in 3D) to accumulate the final sum.","category":"section"},{"location":"theory/#Singular-Integral-Handling","page":"Theory","title":"Singular Integral Handling","text":"One of the primary advantages of Tanh-Sinh quadrature is its ability to handle boundary singularities. Because the transformation maps the endpoints to infinity and clusters points double-exponentially near them, the function is never evaluated exactly at the boundary. For functions like int_0^1 log(x)dx or int_-1^1 (1-x^2)^-12dx, the quadrature typically reaches high accuracy without any special treatment.","category":"section"},{"location":"theory/#Internal-Singularities-and-Domain-Splitting","page":"Theory","title":"Internal Singularities and Domain Splitting","text":"If a singularity exists inside the integration domain (e.g., int_-1^1 x^-12dx at x=0), the standard Tanh-Sinh approach may fail or converge very slowly because the high-density node regions (the \"exponential tails\") are at the boundaries, not the interior.\n\nTo handle this, we provide the quad_split function. It allows the user to specify the location of the internal singularity. The function then:\n\nSplits the domain into sub-regions (2 segments in 1D, 4 rectangles in 2D, or 8 boxes in 3D) where the singularity is on the boundary of each sub-region.\nIntegrates each sub-region using the standard quad function.\nSums the results.\n\nThis transforms an internal singularity into several boundary singularities, which Tanh-Sinh then handles with its characteristic efficiency.","category":"section"},{"location":"examples/advanced/#Advanced-and-Multidimensional-Integration","page":"Advanced Usage","title":"Advanced & Multidimensional Integration","text":"","category":"section"},{"location":"examples/advanced/#1.-Multidimensional-Integration-(2D,-3D)","page":"Advanced Usage","title":"1. Multidimensional Integration (2D, 3D)","text":"FastTanhSinhQuadrature.jl supports multidimensional integration natively.\n\nusing FastTanhSinhQuadrature\nusing StaticArrays\n\n# Define a 2D function f(x, y) = x^2 + y^2\nf_2d(x, y) = x^2 + y^2\n\n# Integration bounds: [-1, 1] x [-1, 1]\nlow = SVector(-1.0, -1.0)\nup  = SVector(1.0, 1.0)\n\n# Generate quadrature scaling\nx, w, h = tanhsinh(Float64, 10)\n\nval_2d = integrate(f_2d, low, up, x, w, h)\nprintln(\"2D Integral: $val_2d\") ","category":"section"},{"location":"examples/advanced/#2.-Pre-computing-Nodes-for-Performance","page":"Advanced Usage","title":"2. Pre-computing Nodes for Performance","text":"For performance-critical code where you integrate many functions or run loops, always pre-calculate the quadrature nodes (x, w, h).\n\n# Pre-calculate once (expensive operation)\nx, w, h = tanhsinh(Float64, 15)\n\n# Reuse many times (cheap operation)\nfor i in 1:100\n    param = i / 100.0\n    f(t) = exp(-param * t^2)\n    val = integrate(f, 0.0, 10.0, x, w, h)\n    # ... use val\nend","category":"section"},{"location":"examples/advanced/#3.-SIMD-Acceleration-with-integrate_avx","page":"Advanced Usage","title":"3. SIMD Acceleration with integrate_avx","text":"For functions compatible with LoopVectorization.jl, you can achieve significant speedups.\n\nusing FastTanhSinhQuadrature\n\nf_poly(x) = x^12 + 3x^5 - 2x\n\nx, w, h = tanhsinh(Float64, 50) # Heavy quadrature\n\n# Standard\n@time integrate(f_poly, x, w, h)\n\n# AVX Optimized\n@time integrate_avx(f_poly, x, w, h) ","category":"section"},{"location":"examples/basics/#Basic-Usage-Examples","page":"Basic Usage","title":"Basic Usage Examples","text":"This section provides practical examples for using FastTanhSinhQuadrature.jl in common scenarios.","category":"section"},{"location":"examples/basics/#1.-Simple-1D-Integration","page":"Basic Usage","title":"1. Simple 1D Integration","text":"Integrating standard mathematical functions is straightforward.\n\nusing FastTanhSinhQuadrature\n\n# Function to integrate: f(x) = exp(-x^2)\nf(x) = exp(-x^2)\n\n# Integrate over [-1, 1]\nresult = integrate(f, 10) # 10 levels of recursion\nprintln(\"Integral of exp(-x^2) on [-1, 1]: $result\")\n\nIntegrating over an arbitrary interval a b:\n\n# Integrate sin(x) from 0 to pi\nresult_sin = integrate(sin, 0.0, π, 10)\nprintln(\"Integral of sin(x) on [0, π]: $result_sin\") # Should be 2.0","category":"section"},{"location":"examples/basics/#2.-High-Precision-Integration-(Double64,-BigFloat)","page":"Basic Usage","title":"2. High Precision Integration (Double64, BigFloat)","text":"One of the main strengths of Tanh-Sinh quadrature is its ability to handle high-precision arithmetic efficiently.\n\nusing FastTanhSinhQuadrature\nusing DoubleFloats\n\nf(x) = exp(x)\n\n# Use Double64 for extended precision\n# N=12 typically gives ~32 digits of precision\nx, w, h = tanhsinh(Double64, 12)\n\n# Integrate exp(x) on [0, 1]\nval = integrate(f, 0.0, 1.0, x, w, h)\nprintln(\"High precision result: $val\")","category":"section"},{"location":"examples/basics/#3.-Dealing-with-Singularities","page":"Basic Usage","title":"3. Dealing with Singularities","text":"Tanh-Sinh quadrature excels at handling endpoint singularities effectively because the quadrature nodes approach the endpoints exponentially fast but never reach them.","category":"section"},{"location":"examples/basics/#Logarithmic-Singularity-log(1-x)","page":"Basic Usage","title":"Logarithmic Singularity log(1-x)","text":"This function has a singularity at x=1.\n\nf_sing(x) = log(1-x)\n\n# Integrate on [-1, 1]\n# The singularity at x=1 is automatically handled\nval = integrate(f_sing, 10) \nprintln(\"Integral of log(1-x) on [-1, 1]: $val\")","category":"section"},{"location":"examples/basics/#Inverse-Square-Root-1/sqrt(x)-at-x0","page":"Basic Usage","title":"Inverse Square Root 1/sqrt(x) at x=0","text":"# Integrate 1/sqrt(x) from 0 to 1\nf_sqrt(x) = 1.0 / sqrt(x)\n\nx, w, h = tanhsinh(Float64, 10)\nval = integrate(f_sqrt, 0.0, 1.0, x, w, h)\nprintln(\"Integral of 1/sqrt(x) on [0, 1]: $val\") # Should be 2.0","category":"section"},{"location":"examples/basics/#4.-Adaptive-Integration","page":"Basic Usage","title":"4. Adaptive Integration","text":"If you require a specific tolerance rather than specifying a fixed number of points, use adaptive_integrate.\n\n# Integrate generic function to 1e-12 tolerance\nval = adaptive_integrate(x -> cos(x)^2, 0.0, 2π, tol=1e-12)\nprintln(val)","category":"section"},{"location":"#FastTanhSinhQuadrature.jl","page":"Home","title":"FastTanhSinhQuadrature.jl","text":"(Image: Stable) (Image: Dev) (Image: Build Status) (Image: Coverage)\n\nFastTanhSinhQuadrature.jl is a high-performance Julia library for numerical integration using the Tanh-Sinh (Double Exponential) quadrature method.\n\nIt handles singularities at endpoints robustly, supports arbitrary precision arithmetic (e.g., BigFloat, Double64), and leverages SIMD for speed.\n\n(Image: Convergence of Tanh-Sinh Quadrature)","category":"section"},{"location":"#Usage-at-a-Glance","page":"Home","title":"Usage at a Glance","text":"using FastTanhSinhQuadrature\n\n# 1. Define function\nf(x) = x * exp(x)\n\n# 2. Integrate on [-1, 1]\nval = integrate(f, 10) # 10 levels\nprintln(val)","category":"section"},{"location":"#Contents","page":"Home","title":"Contents","text":"Theory: Understand the mathematics behind the method.\nBasic Examples: Learn how to integrate simple 1D functions.\nAdvanced Examples: Multidimensional integration and performance tips.\nBenchmarks: Performance comparison against other libraries.\nAPI Reference: Detailed function documentation.\n\n","category":"section"}]
}
